---
title: "Probability Theory and Random Variables"
subtitle: "Randomness and Why You Care"
author: "Hayden Brundage"
date: "11-01-2023"
categories: [code, machine learning, analysis]
image: "standard_deviation.jpg"
jupyter: python3
format:
  html:
    code-fold: true
execute:
    enabled: true
---

![A Continuous Probability Distribution](standard_deviation.jpg)

## Introduction
Understanding probability and statistics is, whether graduate students like it or not, essential to the study of machine learning and artificial intelligence. These fields are inextricably linked and any aspiring AI researcher or data scientist should seek to have a strong foundation in the former two. Computers, and the various algorithms we have developed on them, operate on *data*, which is a fairly ambiguous term here. Data is, in short, a quantity or collection of different values which may exist discretely or continuously. As computers have become exceedingly fast and able to store seemingly endless amounts of information, the absolute volume of data in our world is immense. Data can be as simple as a number or as complex as images and videos. Data may also be intentionally (or unintentionally) generated in a poor manner and as such may not be indicative of anything. As such, any subset of the general data that exists, may not necessarily reflect reality. For example, a misleading dataset might cause one to come to the wrong conclusions about, say, climate change, whereas if you looked at a larger, more inclusive collection of data, a different conclusion may be reached (to be diplomatic, I will not disclose which is which here).

Statisticians and probability theorists have over the centuries developed methods for assessing the quality of and producing data. The work of these great men and women has laid the groundwork for the wonderful fields of probability and statistics. Interacting with data requires that we, as computer scientists, have an understanding of what makes data reliable or "good" in some quality. To be able to accurately assess data and develop intelligent machines to process and reveal further insights from it, it is crucial to study the fields of probability and statistics. In this post, I will cover several fundamental concepts in the space of probability theory with an emphasis on their relation to machine learning. I assume my readers have some familiarity with probability theory in general and much of the this post will be review. 

## Probability and Statistics
Probability is, put simply, the branch of mathematics concerning itself with randomness and its applications in determining the likelihood of events. If you study a technical field, you have likely taken classes or independently learned many concepts within probability theory. Let us begin with a simple example: flipping a coin. The following code simulates 10 coin flips and plots their output:

```{python}
#| label: "fig-coins"
#| fig-cap: "Results from 10 Coin Flips"

import random
import numpy as np
import matplotlib.pyplot as plt

def flipCoin():
    coinFlip = random.randint(0, 1)
    if (coinFlip == 0):
        return "heads"
    else:
        return "tails"

maxFlips = 10
deltaList = []
recordList = []
numHeads = 0
numTails = 0
numFlips = 0

for i in range(maxFlips):
    recordList.append(flipCoin())
    if recordList[i] == "heads":
        numHeads += 1
    else:
        numTails += 1
    numFlips += 1
    deltaList.append((numHeads - numTails) / numFlips)

plt.plot(deltaList)
plt.grid()
plt.axis([1, maxFlips - 1, -1, 1])
plt.xticks(np.arange(len(deltaList)), np.arange(1, len(deltaList) + 1))
plt.xlabel("Number of Coin Flips")
plt.ylabel("Propotion of Flips [(Heads - Tails) / Number of Flips]")
plt.show()
```

It should be obvious that the probability of a coin flip will result in heads is equal to the probability of it being tails. After the first few flips, the above plot should show a trend toward